{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kennethgoodman/hugging_face_dl_course/blob/main/Hugging_Face_DL_Course_Unit_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeDAH0h0EBiG"
      },
      "source": [
        "## Install dependencies and create a virtual screen ðŸ”½\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install swig cmake\n",
        "!pip install -r https://huggingface.co/spaces/ThomasSimonini/temp-space-requirements/raw/main/requirements/requirements-unit1.txt\n",
        "!sudo apt-get update\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ],
      "metadata": {
        "id": "yQIGLPDkGhgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make sure the new installed libraries are used, **sometimes it's required to restart the notebook runtime**. The next cell will force the **runtime to crash, so you'll need to connect again and run the code starting from here**. Thanks for this trick, **we will be able to run our virtual screen.**"
      ],
      "metadata": {
        "id": "TCwBTAwAW9JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "cYvkbef7XEMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "BE5JWP5rQIKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrgpVFqyENVf"
      },
      "source": [
        "## Import the packages ðŸ“¦\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cygWLPGsEQ0m"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "from huggingface_sb3 import load_from_hub, package_to_hub, push_to_hub\n",
        "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
        "from huggingface_sb3 import package_to_hub\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "nS_ui7Gm1aiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "oz0XjiGBoIe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vec_env(env_id, number_of_envs):\n",
        "  return make_vec_env(env_id, n_envs=number_of_envs)\n",
        "\n",
        "envs = [\n",
        "    'LunarLander-v2',\n",
        "    'CartPole-v1',\n",
        "    'FrozenLake-v1-4x4-no_slippery',\n",
        "    'FrozenLake-v1-8x8-no_slippery',\n",
        "    'FrozenLake-v1-4x4', \n",
        "    'FrozenLake-v1-8x8',\n",
        "    'Taxi-v3',\n",
        "    'CarRacing-v0',\n",
        "    'MountainCar-v0',\n",
        "    'SpaceInvadersNoFrameskip-v4',\n",
        "    'BipedalWalker-v3',\n",
        "    'Walker2DBulletEnv-v0',\n",
        "    'AntBulletEnv-v0',\n",
        "    'HalfCheetahBulletEnv-v0'\n",
        "]\n",
        "\n",
        "def get_model_architecture(env_id):\n",
        "  return {\n",
        "  }.get(env_id, 'PPO')\n",
        "\n",
        "def get_model(env_id, number_of_envs=16):\n",
        "  return {\n",
        "      'LunarLander-v2': PPO( # DQN\n",
        "        policy = 'MlpPolicy',\n",
        "        env = get_vec_env(env_id, number_of_envs),\n",
        "        n_steps = 2048,\n",
        "        batch_size = 256,\n",
        "        n_epochs = 16,\n",
        "        gamma = 0.95,\n",
        "        gae_lambda = 0.98,\n",
        "        ent_coef = 0.01,\n",
        "        verbose=1\n",
        "    ),\n",
        "  }.get(env_id,\n",
        "    PPO( # DQN\n",
        "        policy = 'MlpPolicy',\n",
        "        env = get_vec_env(env_id, number_of_envs),\n",
        "        n_steps = 1024,\n",
        "        batch_size = 64,\n",
        "        n_epochs = 4,\n",
        "        gamma = 0.999,\n",
        "        gae_lambda = 0.98,\n",
        "        ent_coef = 0.01,\n",
        "        verbose=1\n",
        "    )\n",
        "  )\n",
        "\n",
        "def get_version_id(env_id):\n",
        "  return {\n",
        "  }.get(env_id, \"0_0_1\")\n",
        "\n",
        "def get_model_name(env_id):\n",
        "  return f\"{env_id}-version_{get_version_id(env_id)}\"\n",
        "\n",
        "def train_and_save(env_id, model, timesteps=1000000):\n",
        "  model.learn(total_timesteps=timesteps)\n",
        "  model.save(get_model_name(env_id))\n",
        "\n",
        "def eval_agent(env_id, model):\n",
        "  # Create a new environment for evaluation\n",
        "  eval_env = gym.make(env_id)\n",
        "\n",
        "  # Evaluate the model with 10 evaluation episodes and deterministic=True\n",
        "  mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "\n",
        "  # Print the results, top=308, 7\n",
        "  print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")  \n",
        "\n",
        "def publish_model(env_id, model):\n",
        "  model_architecture = get_model_architecture(env_id)\n",
        "  repo_id = f\"kennethgoodman/{model_architecture.lower()}-{env_id}\"\n",
        "  commit_message = f\"Upload {model_architecture} {env_id} trained agent\"\n",
        "  eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
        "  package_to_hub(model=model, # Our trained model\n",
        "                model_name=get_model_name(env_id), # The name of our trained model \n",
        "                model_architecture=model_architecture, # The model architecture we used: in our case PPO\n",
        "                env_id=env_id, # Name of the environment\n",
        "                eval_env=eval_env, # Evaluation Environment\n",
        "                repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
        "                commit_message=commit_message)\n",
        "\n",
        "def train_save_eval_and_publish_model(env_id):\n",
        "  model = get_model(env_id)\n",
        "  train_and_save(env_id, model)\n",
        "  eval_agent(env_id, model)\n",
        "  publish_model(env_id, model)\n",
        "  return model"
      ],
      "metadata": {
        "id": "oP4JJ4RroKEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Code"
      ],
      "metadata": {
        "id": "n0qmdfFn2BkF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPG7ofdGIHN8"
      },
      "outputs": [],
      "source": [
        "env_id = 'LunarLander-v2'\n",
        "model = get_model(env_id, 16 * 10)\n",
        "train_and_save(env_id, model, 10_000_000)\n",
        "eval_agent(env_id, model)\n",
        "publish_model(env_id, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading A Model"
      ],
      "metadata": {
        "id": "0rFaQpRxkW29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj8PSGHJfwz3"
      },
      "outputs": [],
      "source": [
        "from huggingface_sb3 import load_from_hub\n",
        "repo_id = \"Classroom-workshop/assignment2-omar\" # The repo_id\n",
        "filename = \"ppo-LunarLander-v2.zip\" # The model filename.zip\n",
        "\n",
        "# When the model was trained on Python 3.8 the pickle protocol is 5\n",
        "# But Python 3.6, 3.7 use protocol 4\n",
        "# In order to get compatibility we need to:\n",
        "# 1. Install pickle5 (we done it at the beginning of the colab)\n",
        "# 2. Create a custom empty object we pass as parameter to PPO.load()\n",
        "custom_objects = {\n",
        "            \"learning_rate\": 0.0,\n",
        "            \"lr_schedule\": lambda _: 0.0,\n",
        "            \"clip_range\": lambda _: 0.0,\n",
        "}\n",
        "\n",
        "checkpoint = load_from_hub(repo_id, filename)\n",
        "model = PPO.load(checkpoint, custom_objects=custom_objects, print_system_info=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs0Y-qgPgLUf"
      },
      "source": [
        "Let's evaluate this agent:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "eval_env = gym.make(\"LunarLander-v2\")\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "id": "PAEVwK-aahfx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "QAN7B0_HCVZC",
        "1bQzQ-QcE3zo",
        "BqPKw3jt_pG5",
        "Avf6gufJBGMw"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "ed7f8024e43d3b8f5ca3c5e1a8151ab4d136b3ecee1e3fd59e0766ccc55e1b10"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}